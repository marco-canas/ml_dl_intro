{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e193b608",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/marco-canas/ml_intro/blob/main/2_planificacion/redes_neuronales_geron/chapter_10/pagina_485_3th_edition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/marco-canas/ml_intro/blob/main/2_planificacion/redes_neuronales_geron/chapter_10/pagina_485_3th_edition.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95106955",
   "metadata": {},
   "source": [
    "Esta es la traducción al español del texto del capítulo 10 de *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow* de Aurélien Géron:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163625df",
   "metadata": {},
   "source": [
    "\n",
    "# **MLPs para Regresión**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3612b45d",
   "metadata": {},
   "source": [
    "\n",
    "En primer lugar, las redes neuronales multicapa (*MLPs*) pueden utilizarse para tareas de regresión. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbf9ec1",
   "metadata": {},
   "source": [
    "Si deseas predecir un único valor (por ejemplo, el precio de una casa dadas varias de sus características), solo necesitas una neurona de salida: su resultado será el valor predicho. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6bb1ff",
   "metadata": {},
   "source": [
    "Para regresión multivariante (es decir, predecir múltiples valores a la vez), necesitas una neurona de salida por cada dimensión de salida. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ea220b",
   "metadata": {},
   "source": [
    "Por ejemplo, para localizar el centro de un objeto en una imagen, necesitas predecir coordenadas en 2D, por lo que requieres dos neuronas de salida. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae77ec62",
   "metadata": {},
   "source": [
    "Si además quieres dibujar un *bounding box* (rectángulo delimitador) alrededor del objeto, necesitas dos números más: el ancho y el alto del objeto. Así, terminarías con cuatro neuronas de salida.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ec6f3e",
   "metadata": {},
   "source": [
    "\n",
    "Scikit-Learn incluye la clase **`MLPRegressor`**, así que vamos a usarla para construir una MLP con tres capas ocultas de 50 neuronas cada una y entrenarla en el conjunto de datos de viviendas de California. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9324a520",
   "metadata": {},
   "source": [
    "Para simplificar, utilizaremos la función **`fetch_california_housing()`** de Scikit-Learn para cargar los datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afc7ca9",
   "metadata": {},
   "source": [
    "Este conjunto es más simple que el que usamos en el Capítulo 2, ya que solo contiene características numéricas (no incluye la característica *ocean_proximity*) y no tiene valores faltantes.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552a3c17",
   "metadata": {},
   "source": [
    "\n",
    "El siguiente código comienza cargando y dividiendo el conjunto de datos, luego crea un *pipeline* para estandarizar las características de entrada antes de pasarlas al **`MLPRegressor`**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dd625b",
   "metadata": {},
   "source": [
    "Esto es muy importante para las redes neuronales, ya que se entrenan mediante *gradiente descendente*, y como vimos en el Capítulo 4, el gradiente descendente no converge bien cuando las características tienen escalas muy diferentes.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e757d545",
   "metadata": {},
   "source": [
    "\n",
    "Finalmente, el código entrena el modelo y evalúa su error de validación. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dc20e0",
   "metadata": {},
   "source": [
    "El modelo usa la función de activación **ReLU** en las capas ocultas y una variante del gradiente descendente llamada **Adam** (ver Capítulo 11) para minimizar el *error cuadrático medio (MSE)*, con un poco de regularización **ℓ₂** (controlable mediante el hiperparámetro **`alpha`**):  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f96c7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import fetch_california_housing # obtención del \n",
    "from sklearn.metrics import root_mean_squared_error # métrica de error\n",
    "from sklearn.model_selection import train_test_split # división de datos\n",
    "from sklearn.neural_network import MLPRegressor # red neuronal\n",
    "from sklearn.pipeline import make_pipeline # pipeline\n",
    "from sklearn.preprocessing import StandardScaler # escalado de datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa407f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "housing = fetch_california_housing() # obtención del dataset california_housing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00329fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7529b3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.keys() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3230070",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a36abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "def load_housing_data():\n",
    "    tarball_path = Path(\"datasets/housing.tgz\")\n",
    "    if not tarball_path.is_file():\n",
    "        Path(\"datasets\").mkdir(parents=True, exist_ok=True)\n",
    "        url = \"https://github.com/ageron/data/raw/main/housing.tgz\"\n",
    "        urllib.request.urlretrieve(url, tarball_path)\n",
    "    with tarfile.open(tarball_path) as housing_tarball:\n",
    "            housing_tarball.extractall(path=\"datasets\")\n",
    "    return pd.read_csv(Path(\"datasets/housing/housing.csv\"))\n",
    "\n",
    "housing_geron = load_housing_data()\n",
    "housing_geron.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317aa84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3441bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%time \n",
    "mlp_reg = MLPRegressor(hidden_layer_sizes=[50, 50, 50], random_state=42) # instancia MLPRegressor con 3 capas ocultas de 50 neuronas cada una\n",
    "pipeline = make_pipeline(StandardScaler(), mlp_reg) # creamos un pipeline con escalado estandar y el modelo mlp_reg\n",
    "pipeline.fit(X_train, y_train) # entrenar el pipeline con los datos de entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42039d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = pipeline.predict(X_valid)\n",
    "rmse = root_mean_squared_error(y_valid, y_pred)  # ~0.505\n",
    "10_000*rmse  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d20037",
   "metadata": {},
   "source": [
    "\n",
    "Obtenemos un **RMSE de validación** de aproximadamente **0.505**, comparable al rendimiento de un *Random Forest*. ¡Nada mal para un primer intento!  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb97ea6",
   "metadata": {},
   "source": [
    "\n",
    "Cabe destacar que esta MLP **no usa ninguna función de activación en la capa de salida**, por lo que puede generar cualquier valor. Esto suele ser aceptable, pero si necesitas garantizar que la salida siempre sea positiva, deberías usar **ReLU** o **softplus** (una variante suave de ReLU: *softplus(z) = log(1 + exp(z))*). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451fc548",
   "metadata": {},
   "source": [
    "La función softplus es cercana a 0 cuando *z* es negativo y cercana a *z* cuando es positivo.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdb6dd5",
   "metadata": {},
   "source": [
    "\n",
    "Por último, si quieres asegurar que las predicciones estén dentro de un rango específico, puedes usar **sigmoid** (para valores entre 0 y 1) o **tanh** (entre –1 y 1) y escalar los objetivos acordemente. Lamentablemente, **`MLPRegressor` no soporta funciones de activación en la capa de salida**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719a9403",
   "metadata": {},
   "source": [
    "\n",
    "# ⚠ **Advertencia**  \n",
    "Construir y entrenar una MLP estándar con Scikit-Learn en pocas líneas de código es muy conveniente, pero sus capacidades son limitadas. Por eso, más adelante en este capítulo pasaremos a **Keras**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb6c85b",
   "metadata": {},
   "source": [
    "\n",
    "La clase **`MLPRegressor`** usa el *error cuadrático medio (MSE)*, que suele ser adecuado para regresión. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6306e4",
   "metadata": {},
   "source": [
    "Sin embargo, si hay muchos *outliers* en los datos, podrías preferir el *error absoluto medio (MAE)* o la **pérdida de Huber**, que combina MSE y MAE: es cuadrática para errores menores que un umbral **δ** (típicamente 1) y lineal para errores mayores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de5ded7",
   "metadata": {},
   "source": [
    " La parte lineal la hace menos sensible a *outliers* que el MSE, mientras que la parte cuadrática permite una convergencia más rápida que el MAE. No obstante, **`MLPRegressor` solo soporta MSE**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c69fbc3",
   "metadata": {},
   "source": [
    "\n",
    "La **Tabla 10-1** resume la arquitectura típica de una MLP para regresión.  \n",
    "\n",
    "| **Hiperparámetro**         | **Valor típico**                                                                 |\n",
    "|----------------------------|----------------------------------------------------------------------------------|\n",
    "| N° de capas ocultas        | Depende del problema (usualmente 1 a 5)                                          |\n",
    "| N° de neuronas por capa    | Depende del problema (usualmente 10 a 100)                                       |\n",
    "| N° de neuronas de salida   | 1 por dimensión de predicción                                                    |\n",
    "| Activación en capas ocultas| ReLU                                                                             |\n",
    "| Activación en salida       | Ninguna, ReLU/softplus (salidas positivas) o sigmoid/tanh (salidas acotadas)     |\n",
    "| Función de pérdida         | MSE, o Huber si hay *outliers*                                                   |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40809b95",
   "metadata": {},
   "source": [
    "\n",
    "Espero que esta traducción te sea útil. Si necesitas ajustes o más detalles, ¡avísame!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9691c2",
   "metadata": {},
   "source": [
    "Aquí tienes una **secuencia didáctica** para practicar la implementación de **MLPs para regresión** en Python, basada en el texto anterior. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea902b49",
   "metadata": {},
   "source": [
    "La secuencia está diseñada para avanzar desde conceptos básicos hasta técnicas más avanzadas, con ejercicios prácticos en cada etapa.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad967611",
   "metadata": {},
   "source": [
    "\n",
    "## **Secuencia Didáctica: MLPs para Regresión en Python**  \n",
    "**Objetivo:** Implementar y optimizar una red neuronal multicapa (*MLP*) para problemas de regresión usando `scikit-learn` y `Keras`.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdf0a7e",
   "metadata": {},
   "source": [
    "\n",
    "### **1. Introducción a los Datos y Preprocesamiento**  \n",
    "**Objetivo:** Familiarizarse con el dataset y preparar los datos para el modelo.  \n",
    "\n",
    "**Ejercicios:**  \n",
    "1. **Cargar y explorar el dataset**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be571ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "df[\"Target\"] = housing.target\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de91a37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9aebc57",
   "metadata": {},
   "source": [
    "\n",
    "2. **División del dataset (train/validation/test)**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c96383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state=42\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b874d97c",
   "metadata": {},
   "source": [
    "\n",
    "3. **Estandarización de características**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f58820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0444f2db",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### **2. Implementación Básica con `MLPRegressor` (Scikit-Learn)**  \n",
    "**Objetivo:** Entrenar un primer modelo de MLP y evaluar su rendimiento.  \n",
    "\n",
    "**Ejercicios:**  \n",
    "1. **Entrenar un MLP básico**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ee33083",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mneural_network\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MLPRegressor\n\u001b[32m      3\u001b[39m mlp_reg = MLPRegressor(hidden_layer_sizes=[\u001b[32m50\u001b[39m, \u001b[32m50\u001b[39m, \u001b[32m50\u001b[39m], random_state=\u001b[32m42\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m mlp_reg.fit(\u001b[43mX_train_scaled\u001b[49m, y_train)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp_reg = MLPRegressor(hidden_layer_sizes=[50, 50, 50], random_state=42)\n",
    "mlp_reg.fit(X_train_scaled, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a1f587",
   "metadata": {},
   "source": [
    "\n",
    "2. **Evaluar el modelo (RMSE)**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21980591",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlp_reg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m root_mean_squared_error\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m y_pred = \u001b[43mmlp_reg\u001b[49m.predict(X_valid_scaled)\n\u001b[32m      4\u001b[39m rmse = root_mean_squared_error(y_valid, y_pred)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# Debería ser ~0.505\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'mlp_reg' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "y_pred = mlp_reg.predict(X_valid_scaled)\n",
    "rmse = root_mean_squared_error(y_valid, y_pred)\n",
    "print(f\"RMSE: {rmse:.3f}\")  # Debería ser ~0.505\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53e391c",
   "metadata": {},
   "source": [
    "\n",
    "3. **Experimentar con diferentes arquitecturas**  \n",
    "   - Probar con más/menos capas ocultas.  \n",
    "   - Cambiar el número de neuronas (ej. `[100, 50]`).  \n",
    "   - Observar cómo afecta al rendimiento.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce70754",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **3. Optimización del Modelo**  \n",
    "**Objetivo:** Mejorar el rendimiento del MLP ajustando hiperparámetros.  \n",
    "\n",
    "**Ejercicios:**  \n",
    "1. **Ajustar la tasa de aprendizaje y el optimizador**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c2db3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_reg = MLPRegressor(\n",
    "    hidden_layer_sizes=[50, 50, 50],\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",  # Usar Adam en lugar de SGD\n",
    "    learning_rate_init=0.001,  # Tasa de aprendizaje más baja\n",
    "    max_iter=500,  # Más épocas\n",
    "    random_state=42\n",
    ")\n",
    "mlp_reg.fit(X_train_scaled, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe676cd",
   "metadata": {},
   "source": [
    "\n",
    "2. **Regularización (L2) para evitar overfitting** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "475d689d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MLPRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m mlp_reg = \u001b[43mMLPRegressor\u001b[49m(\n\u001b[32m      2\u001b[39m     hidden_layer_sizes=[\u001b[32m50\u001b[39m, \u001b[32m50\u001b[39m, \u001b[32m50\u001b[39m],\n\u001b[32m      3\u001b[39m     alpha=\u001b[32m0.01\u001b[39m,  \u001b[38;5;66;03m# Factor de regularización L2\u001b[39;00m\n\u001b[32m      4\u001b[39m     random_state=\u001b[32m42\u001b[39m\n\u001b[32m      5\u001b[39m )\n\u001b[32m      6\u001b[39m mlp_reg.fit(X_train_scaled, y_train)\n",
      "\u001b[31mNameError\u001b[39m: name 'MLPRegressor' is not defined"
     ]
    }
   ],
   "source": [
    " \n",
    "mlp_reg = MLPRegressor(\n",
    "    hidden_layer_sizes=[50, 50, 50],\n",
    "    alpha=0.01,  # Factor de regularización L2\n",
    "    random_state=42\n",
    ")\n",
    "mlp_reg.fit(X_train_scaled, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88893e6b",
   "metadata": {},
   "source": [
    "\n",
    "3. **Early Stopping (usando `validation_fraction`)**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76db05d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_reg = MLPRegressor(\n",
    "    hidden_layer_sizes=[50, 50, 50],\n",
    "    early_stopping=True,  # Detener si no mejora\n",
    "    validation_fraction=0.2,  # 20% de validación\n",
    "    random_state=42\n",
    "   )\n",
    "mlp_reg.fit(X_train_scaled, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7300fdc7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### **4. Implementación con Keras (TensorFlow) para Mayor Flexibilidad**  \n",
    "**Objetivo:** Usar Keras para modelos más personalizables (ej. activaciones en la capa de salida).  \n",
    "\n",
    "**Ejercicios:**  \n",
    "1. **Crear un MLP con Keras**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a33acb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(50, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(50, activation=\"relu\"),\n",
    "    keras.layers.Dense(50, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)  # Sin activación (regresión)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff96d78",
   "metadata": {},
   "source": [
    "\n",
    "2. **Entrenar y evaluar el modelo** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdf4671",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "history = model.fit(\n",
    "       X_train_scaled, y_train,\n",
    "       epochs=50,\n",
    "       validation_data=(X_valid_scaled, y_valid)\n",
    "   )\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(f\"RMSE (Keras): {rmse:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a7a9fa",
   "metadata": {},
   "source": [
    "\n",
    "3. **Probar diferentes funciones de activación en la salida**  \n",
    "   - **ReLU/Softplus** (si la salida debe ser positiva): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7958528c",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "keras.layers.Dense(1, activation=\"softplus\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86606cf5",
   "metadata": {},
   "source": [
    "   - **Sigmoid/Tanh** (si la salida debe estar acotada):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c824ccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "keras.layers.Dense(1, activation=\"sigmoid\")  # Escalar 'y' entre 0 y 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da349f6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### **5. Experimentación Avanzada (Opcional)**  \n",
    "**Objetivo:** Profundizar en técnicas avanzadas para mejorar el modelo.  \n",
    "\n",
    "**Ejercicios:**  \n",
    "1. **Usar Batch Normalization** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f69d8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7344e133",
   "metadata": {},
   "source": [
    "2. **Probar Dropout para regularización** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24909bd",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc48d533",
   "metadata": {},
   "source": [
    "3. **Optimización con GridSearchCV (Scikit-Learn)**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8937f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"hidden_layer_sizes\": [(50,), (100, 50)],\n",
    "    \"alpha\": [0.0001, 0.001, 0.01],\n",
    "}\n",
    "grid_search = GridSearchCV(MLPRegressor(), param_grid, cv=3)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc1a9d4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## **Resumen de la Secuencia**  \n",
    "1. **Preprocesamiento**: Estandarización y división de datos.  \n",
    "2. **Primer modelo con Scikit-Learn**: Entrenamiento y evaluación básica.  \n",
    "3. **Optimización**: Ajuste de hiperparámetros y regularización.  \n",
    "4. **Keras**: Modelos más flexibles y personalizables.  \n",
    "5. **Avanzado**: BatchNorm, Dropout y búsqueda de hiperparámetros.  \n",
    "\n",
    "Esta secuencia permite pasar de **conceptos básicos** a **técnicas avanzadas**, con ejercicios prácticos en cada paso. ¿Quieres que profundicemos en algún tema en particular?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a8eed9",
   "metadata": {},
   "source": [
    "# Referentes en Deep Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67277d2",
   "metadata": {},
   "source": [
    "Aquí tienes **10 referentes clave** en *deep learning* para enriquecer tu docencia e investigación en matemáticas, ciencia de datos y métodos cuanti/cuali en la Universidad de Antioquia (Seccional Bajo Cauca). Estos recursos incluyen cursos, libros, investigadores y enfoques innovadores, basados en las tendencias actuales y futuras del campo :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f077f8ae",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### **1. Cursos y Programas Académicos**  \n",
    "- **Curso \"Bases Matemáticas del Deep Learning\" (TECH Universidad Tecnológica)**:  \n",
    "  Enfocado en fundamentos matemáticos (álgebra lineal, optimización, backpropagation) y aplicaciones prácticas con metodología *Relearning*. Ideal para docencia en matemáticas aplicadas .  \n",
    "- **Track en Ciencia de Datos (Colegio Bourbaki)**:  \n",
    "  Cubre desde probabilidad bayesiana hasta redes neuronales avanzadas (CNNs, Transformers, GANs). Incluye proyectos prácticos y evaluación basada en problemas reales .  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adf2cf9",
   "metadata": {},
   "source": [
    "\n",
    "### **2. Investigadores y Expertos**  \n",
    "- **Geoffrey Hinton & Yann LeCun**:  \n",
    "  Pioneros en redes neuronales y aprendizaje no supervisado. Explora sus trabajos recientes en *capsule networks* y autoaprendizaje (*self-supervised learning*) .  \n",
    "- **Gary Marcus**:  \n",
    "  Crítico del *deep learning* puro; promueve modelos híbridos (neuro-simbólicos) que integran razonamiento abstracto y conocimiento previo. Útil para discutir limitaciones del enfoque actual .  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0a4b6b",
   "metadata": {},
   "source": [
    "\n",
    "### **3. Frameworks y Herramientas**  \n",
    "- **TensorFlow/Keras y PyTorch**:  \n",
    "  Los más usados en docencia. PyTorch es ideal para investigación por su flexibilidad en redes personalizadas .  \n",
    "- **Libro: \"Deep Learning\" (Ian Goodfellow et al.)**:  \n",
    "  Biblia técnica que cubre fundamentos matemáticos (gradientes, regularización) y arquitecturas avanzadas (GANs, RNNs) .  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e9dd9b",
   "metadata": {},
   "source": [
    "\n",
    "### **4. Tendencias Futuras**  \n",
    "- **Aprendizaje Autosupervisado (*Self-Supervised Learning*)**:  \n",
    "  Reducción de dependencia de datos etiquetados. Ejemplo: modelos de lenguaje como BERT/GPT .  \n",
    "- **Redes Generativas (GANs y Difusión Estable)**:  \n",
    "  Aplicaciones en generación de imágenes y datos sintéticos para investigación cualitativa .  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a2c8d5",
   "metadata": {},
   "source": [
    "\n",
    "### **5. Métodos Híbridos para Investigación**  \n",
    "- **Física + Deep Learning**:  \n",
    "  Modelos que integran leyes físicas en redes neuronales (ej.: predicción climática). Relevante para proyectos interdisciplinarios .  \n",
    "- **Ética en IA**:  \n",
    "  Módulos sobre sesgos algorítmicos y justicia social, clave en investigación cualitativa .  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d83c0d9",
   "metadata": {},
   "source": [
    "\n",
    "### **6. Recursos Locales (Colombia)**  \n",
    "- **Grupo GIPI (UdeA)**:  \n",
    "  Enfoque en ingeniería de procesos con IA. Colaboración potencial para proyectos aplicados .  \n",
    "- **Sergio Gutiérrez (UdeA)**:  \n",
    "  Investigador en redes neuronales para detección de intrusiones. Sus publicaciones ofrecen casos prácticos en seguridad .  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a775d7",
   "metadata": {},
   "source": [
    "\n",
    "### **Recomendaciones para Implementación** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee45aca",
   "metadata": {},
   "source": [
    " \n",
    "1. **En Docencia**: Usa ejemplos de *few-shot learning* (aprendizaje con pocos datos) para clases en entornos con recursos limitados .  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2033cb",
   "metadata": {},
   "source": [
    "2. **En Investigación**: Combina técnicas cuanti (análisis de RMSE en modelos) con cuali (interpretación de resultados con *attention maps* en CNNs) . "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a68b62",
   "metadata": {},
   "source": [
    " \n",
    "3. **Talleres Prácticos**:  \n",
    "   - \"Cómo entrenar un modelo de NLP con BERT\" (usando datasets en español).  \n",
    "   - \"Visualización de gradientes en redes convolucionales\" (para explicar matemáticas subyacentes) .  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c3eef0",
   "metadata": {},
   "source": [
    "\n",
    "Estos referentes te permitirán actualizar tus cursos, integrar investigación aplicada y fomentar un enfoque crítico en el uso de IA. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb4015a",
   "metadata": {},
   "source": [
    "Para profundizar, explora los enlaces directos a los recursos citados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cd873c",
   "metadata": {},
   "source": [
    "# Referentes en la constitución de este cuaderno  \n",
    "\n",
    "* [End to End machine learning project][https://github.com/ageron/handson-ml3/blob/main/02_end_to_end_machine_learning_project.ipynb]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9343b5ee",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
