{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65254a90",
   "metadata": {},
   "source": [
    "AquÃ­ tienes la traducciÃ³n al espaÃ±ol del texto:\n",
    "\n",
    "---\n",
    "\n",
    "### El PerceptrÃ³n Multicapa y la RetropropagaciÃ³n  \n",
    "\n",
    "Un **PerceptrÃ³n Multicapa (MLP)** estÃ¡ compuesto por una capa de entrada, una o mÃ¡s capas de **Unidades Lineales Umbral (TLU)** llamadas **capas ocultas**, y una capa final de TLUs llamada **capa de salida** (ver Figura 10-7). Las capas cercanas a la entrada suelen llamarse **capas inferiores**, y las cercanas a las salidas, **capas superiores**.  \n",
    "\n",
    "**Figura 10-7.** Arquitectura de un perceptrÃ³n multicapa con dos entradas, una capa oculta de cuatro neuronas y tres neuronas de salida.  \n",
    "\n",
    "**NOTA**  \n",
    "El flujo de la seÃ±al solo va en una direcciÃ³n (de las entradas a las salidas), por lo que esta arquitectura es un ejemplo de una **red neuronal de propagaciÃ³n hacia adelante (FNN)**.  \n",
    "\n",
    "Cuando una **red neuronal artificial (ANN)** contiene una pila profunda de capas ocultas, se llama **red neuronal profunda (DNN)**. El campo del **aprendizaje profundo** estudia las DNNs y, en general, se enfoca en modelos con pilas profundas de cÃ¡lculos. Aun asÃ­, muchas personas hablan de aprendizaje profundo cada vez que se mencionan redes neuronales (incluso las superficiales).  \n",
    "\n",
    "Durante muchos aÃ±os, los investigadores lucharon por encontrar una forma de entrenar MLPs sin Ã©xito. A principios de los 60, varios investigadores discutieron la posibilidad de usar **descenso de gradiente** para entrenar redes neuronales, pero, como vimos en el CapÃ­tulo 4, esto requiere calcular los gradientes del error del modelo respecto a sus parÃ¡metros. En ese entonces no estaba claro cÃ³mo hacer esto eficientemente en un modelo tan complejo con tantos parÃ¡metros, especialmente con la capacidad computacional de la Ã©poca.  \n",
    "\n",
    "En 1970, un investigador llamado **Seppo Linnainmaa** presentÃ³ en su tesis de maestrÃ­a una tÃ©cnica para calcular todos los gradientes de forma automÃ¡tica y eficiente. Este algoritmo se conoce hoy como **diferenciaciÃ³n automÃ¡tica en modo inverso** (o **autodiff inverso**). En solo dos pasadas por la red (una hacia adelante y otra hacia atrÃ¡s), puede calcular los gradientes del error de la red neuronal respecto a cada parÃ¡metro del modelo. Es decir, determina cÃ³mo ajustar cada peso de conexiÃ³n y cada sesgo para reducir el error. Estos gradientes se usan luego para realizar un paso de descenso de gradiente. Si se repite este proceso (calcular gradientes automÃ¡ticamente y ajustar con descenso de gradiente), el error de la red neuronal disminuirÃ¡ gradualmente hasta alcanzar un mÃ­nimo. Esta combinaciÃ³n de autodiff inverso y descenso de gradiente se llama **retropropagaciÃ³n** (o **backprop**).  \n",
    "\n",
    "**NOTA**  \n",
    "Existen varias tÃ©cnicas de autodiff, cada una con pros y contras. El autodiff inverso es ideal cuando la funciÃ³n a diferenciar tiene muchas variables (pesos y sesgos) y pocas salidas (una pÃ©rdida).  \n",
    "\n",
    "La retropropagaciÃ³n puede aplicarse a todo tipo de grafos computacionales, no solo a redes neuronales: la tesis de Linnainmaa no trataba especÃ­ficamente de redes neuronales, sino de un concepto mÃ¡s general. Pasaron varios aÃ±os antes de que la retropropagaciÃ³n se usara ampliamente en redes neuronales.  \n",
    "\n",
    "En 1985, **David Rumelhart, Geoffrey Hinton y Ronald Williams** publicaron un artÃ­culo revolucionario que analizaba cÃ³mo la retropropagaciÃ³n permitÃ­a a las redes neuronales aprender representaciones internas Ãºtiles. Sus resultados fueron tan impactantes que la retropropagaciÃ³n se popularizÃ³ rÃ¡pidamente. Hoy es, por mucho, la tÃ©cnica de entrenamiento mÃ¡s usada en redes neuronales.  \n",
    "\n",
    "### Funcionamiento detallado de la retropropagaciÃ³n:  \n",
    "1. **Mini-lotes**: Procesa un mini-lote a la vez (ej. 32 instancias) y recorre el conjunto de entrenamiento mÃºltiples veces. Cada pasada se llama **Ã©poca**.  \n",
    "2. **Pasada hacia adelante**: El mini-lote entra por la capa de entrada, y se calcula la salida de cada neurona en las capas ocultas, preservando todos los resultados intermedios para la pasada hacia atrÃ¡s.  \n",
    "3. **CÃ¡lculo del error**: Se mide el error de salida usando una **funciÃ³n de pÃ©rdida** que compara la salida deseada con la real.  \n",
    "4. **Pasada hacia atrÃ¡s**: Usando la **regla de la cadena**, el algoritmo calcula cuÃ¡nto contribuyÃ³ cada peso y sesgo al error, propagando el gradiente del error desde la salida hasta la entrada.  \n",
    "5. **Ajuste de pesos**: Finalmente, se realiza un paso de descenso de gradiente para ajustar los pesos y reducir el error.  \n",
    "\n",
    "**ADVERTENCIA**  \n",
    "Es crucial inicializar los pesos de las capas ocultas de forma **aleatoria**, de lo contrario el entrenamiento fallarÃ¡. Si todos los pesos y sesgos empiezan en cero, todas las neuronas en una capa serÃ¡n idÃ©nticas, y la retropropagaciÃ³n las ajustarÃ¡ igual, manteniendo la simetrÃ­a. Esto harÃ­a que la red actÃºe como si tuviera solo una neurona por capa. La inicializaciÃ³n aleatoria rompe esta simetrÃ­a y permite que la red aprenda diversidad.  \n",
    "\n",
    "En resumen, la retropropagaciÃ³n hace predicciones (pasada hacia adelante), mide el error, calcula las contribuciones al error por capa (pasada hacia atrÃ¡s) y ajusta los pesos (descenso de gradiente).  \n",
    "\n",
    "### Activaciones no lineales:  \n",
    "Para que la retropropagaciÃ³n funcione, Rumelhart y sus colegas reemplazaron la **funciÃ³n escalÃ³n** por la **funciÃ³n logÃ­stica** (Ïƒ(z) = 1 / (1 + exp(â€“z)), tambiÃ©n llamada **sigmoide**). La funciÃ³n escalÃ³n tiene gradiente cero en todos lados (imposibilitando el descenso de gradiente), mientras que la sigmoide tiene un gradiente bien definido.  \n",
    "\n",
    "Otras funciones de activaciÃ³n populares:  \n",
    "- **Tangente hiperbÃ³lica (tanh)**: Similar a la sigmoide, pero con rango de â€“1 a 1, lo que acelera la convergencia.  \n",
    "- **Unidad Lineal Rectificada (ReLU)**: ReLU(z) = max(0, z). No es diferenciable en z = 0, pero en la prÃ¡ctica es eficiente y evita algunos problemas de gradiente.  \n",
    "\n",
    "**Â¿Por quÃ© son necesarias las funciones de activaciÃ³n?**  \n",
    "Si solo se encadenan transformaciones lineales, el resultado sigue siendo lineal. Las activaciones no lineales permiten a las redes aproximar funciones complejas. Una DNN suficientemente grande con activaciones no lineales puede, en teorÃ­a, aproximar cualquier funciÃ³n continua.  \n",
    "\n",
    "**Figura 10-8.** Funciones de activaciÃ³n (izq.) y sus derivadas (der.).  \n",
    "\n",
    "Â¡Listo! Ahora conoces el origen de las redes neuronales, su arquitectura, cÃ³mo se calculan sus salidas y el algoritmo de retropropagaciÃ³n. Pero... Â¿para quÃ© sirven exactamente?  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377718d0",
   "metadata": {},
   "source": [
    "\n",
    "### Notas adicionales:  \n",
    "- Se mantuvieron tÃ©rminos tÃ©cnicos como *backpropagation* (retropropagaciÃ³n) y *ReLU* por ser ampliamente usados en espaÃ±ol.  \n",
    "- Se ajustaron ejemplos y fÃ³rmulas para claridad, conservando su significado original.  \n",
    "- El estilo es tÃ©cnico pero accesible, dirigido a lectores con conocimientos bÃ¡sicos de machine learning.  \n",
    "\n",
    "Â¿Necesitas ajustes o mÃ¡s detalles en alguna secciÃ³n?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad7b891",
   "metadata": {},
   "source": [
    "# PrÃ¡ctica de codificaciÃ³n  \n",
    "\n",
    "AquÃ­ tienes una **prÃ¡ctica de codificaciÃ³n en Python** enfocada en redes neuronales multicapa (MLP) usando `TensorFlow/Keras`, que cubre los conceptos clave del texto traducido:  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e724ba2",
   "metadata": {},
   "source": [
    "\n",
    "### **PrÃ¡ctica: ImplementaciÃ³n de un PerceptrÃ³n Multicapa (MLP) con RetropropagaciÃ³n**  \n",
    "**Objetivos:**  \n",
    "1. Crear un MLP secuencial para clasificaciÃ³n.  \n",
    "2. Entender el papel de las funciones de activaciÃ³n no lineales.  \n",
    "3. Visualizar el impacto de la inicializaciÃ³n de pesos.  \n",
    "4. Monitorizar el entrenamiento con retropropagaciÃ³n.  \n",
    "\n",
    "---  \n",
    "\n",
    "### **Paso 1: ConfiguraciÃ³n del Entorno**  \n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.initializers import RandomUniform, Zeros\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "```\n",
    "\n",
    "### **Paso 2: GeneraciÃ³n de Datos**  \n",
    "Usamos el dataset `make_moons` para un problema de clasificaciÃ³n no lineal:  \n",
    "```python\n",
    "X, y = make_moons(n_samples=1000, noise=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis')\n",
    "plt.title(\"Dataset de ClasificaciÃ³n No Lineal\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### **Paso 3: ImplementaciÃ³n del MLP con Keras**  \n",
    "#### **Modelo Secuencial con:**  \n",
    "- Capa oculta (4 neuronas, activaciÃ³n ReLU).  \n",
    "- Capa de salida (1 neurona, activaciÃ³n sigmoide).  \n",
    "- FunciÃ³n de pÃ©rdida: `binary_crossentropy` (para clasificaciÃ³n binaria).  \n",
    "- Optimizador: `Adam` (variante de descenso de gradiente).  \n",
    "\n",
    "```python\n",
    "model = Sequential([\n",
    "    Dense(4, activation='relu', input_shape=(2,), kernel_initializer=RandomUniform(minval=-0.5, maxval=0.5)),\n",
    "    Dense(1, activation='sigmoid', kernel_initializer=RandomUniform(minval=-0.5, maxval=0.5))\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "### **Paso 4: Entrenamiento con RetropropagaciÃ³n**  \n",
    "```python\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "```\n",
    "\n",
    "### **Paso 5: VisualizaciÃ³n de Resultados**  \n",
    "#### **Curvas de Aprendizaje:**  \n",
    "```python\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Test Loss')\n",
    "plt.xlabel('Ã‰pocas')\n",
    "plt.ylabel('PÃ©rdida')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### **Frontera de DecisiÃ³n:**  \n",
    "```python\n",
    "def plot_decision_boundary(model, X, y):\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, levels=0.5, cmap='RdBu')\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap='viridis')\n",
    "    plt.title(\"Frontera de DecisiÃ³n del MLP\")\n",
    "    plt.show()\n",
    "\n",
    "plot_decision_boundary(model, X_test, y_test)\n",
    "```\n",
    "\n",
    "### **Paso 6: Experimentos Adicionales**  \n",
    "#### **1. InicializaciÃ³n de Pesos a Cero (Â¡Advertencia!)**  \n",
    "```python\n",
    "model_zero_init = Sequential([\n",
    "    Dense(4, activation='relu', input_shape=(2,), kernel_initializer=Zeros()),\n",
    "    Dense(1, activation='sigmoid', kernel_initializer=Zeros())\n",
    "])\n",
    "model_zero_init.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "model_zero_init.fit(X_train, y_train, epochs=100, verbose=0)\n",
    "print(\"PrecisiÃ³n con pesos en cero:\", accuracy_score(y_test, model_zero_init.predict(X_test) > 0.5))\n",
    "```\n",
    "\n",
    "#### **2. ComparaciÃ³n de Funciones de ActivaciÃ³n**  \n",
    "```python\n",
    "activations = ['relu', 'tanh', 'sigmoid']\n",
    "for activation in activations:\n",
    "    model_act = Sequential([\n",
    "        Dense(4, activation=activation, input_shape=(2,)),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model_act.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    model_act.fit(X_train, y_train, epochs=100, verbose=0)\n",
    "    print(f\"PrecisiÃ³n con {activation}:\", accuracy_score(y_test, model_act.predict(X_test) > 0.5))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusiones de la PrÃ¡ctica:**  \n",
    "- **RetropropagaciÃ³n:** El modelo ajusta automÃ¡ticamente los pesos mediante `model.fit()`.  \n",
    "- **Funciones de ActivaciÃ³n:** ReLU suele ser mÃ¡s eficiente que sigmoide/tanh en capas ocultas.  \n",
    "- **InicializaciÃ³n:** Los pesos aleatorios rompen la simetrÃ­a y permiten el aprendizaje.  \n",
    "- **Batch y Ã‰pocas:** El mini-batch (`batch_size=32`) acelera el entrenamiento.  \n",
    "\n",
    "**Salida Esperada:**  \n",
    "- GrÃ¡ficos de pÃ©rdida decreciente.  \n",
    "- Frontera de decisiÃ³n no lineal que separa las clases.  \n",
    "- PrecisiÃ³n > 90% con inicializaciÃ³n adecuada.  \n",
    "\n",
    "---  \n",
    "\n",
    "**Â¿QuÃ© mÃ¡s te gustarÃ­a explorar?** Por ejemplo:  \n",
    "- AÃ±adir mÃ¡s capas ocultas para crear una DNN.  \n",
    "- RegularizaciÃ³n con Dropout.  \n",
    "- OptimizaciÃ³n de hiperparÃ¡metros.  \n",
    "\n",
    "Â¡Espero que esta prÃ¡ctica te ayude a dominar los MLPs! ğŸš€"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
