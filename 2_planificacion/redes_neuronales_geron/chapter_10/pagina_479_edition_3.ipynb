{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4838a09",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/marco-canas/ml_intro/blob/main/2_planificacion/redes_neuronales_geron/chapter_10/pagina_479_edition_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/marco-canas/ml_intro/blob/main/2_planificacion/redes_neuronales_geron/chapter_10/pagina_479_edition_3.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65254a90",
   "metadata": {},
   "source": [
    "Aqu√≠ tienes la traducci√≥n al espa√±ol del texto:\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0fbc22",
   "metadata": {},
   "source": [
    "\n",
    "### El Perceptr√≥n Multicapa y la Retropropagaci√≥n  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d545218a",
   "metadata": {},
   "source": [
    "\n",
    "Un **Perceptr√≥n Multicapa (MLP)** est√° compuesto por una capa de entrada, una o m√°s capas de **Unidades Lineales Umbral (TLU)** llamadas **capas ocultas**, y una capa final de TLUs llamada **capa de salida** (ver Figura 10-7). Las capas cercanas a la entrada suelen llamarse **capas inferiores**, y las cercanas a las salidas, **capas superiores**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad80aa4",
   "metadata": {},
   "source": [
    "<img src = 'perceptron_multicapa_1.png' width = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d15a22",
   "metadata": {},
   "source": [
    "\n",
    "**Figura 10-7.** Arquitectura de un perceptr√≥n multicapa con dos entradas, una capa oculta de cuatro neuronas y tres neuronas de salida.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a202a07c",
   "metadata": {},
   "source": [
    "\n",
    "**NOTA**  \n",
    "El flujo de la se√±al solo va en una direcci√≥n (de las entradas a las salidas), por lo que esta arquitectura es un ejemplo de una **red neuronal de propagaci√≥n hacia adelante (FNN)**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e425a83a",
   "metadata": {},
   "source": [
    "\n",
    "Cuando una **red neuronal artificial (ANN)** contiene una pila profunda de capas ocultas, se llama **red neuronal profunda (DNN)**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb097f7d",
   "metadata": {},
   "source": [
    "El campo del **aprendizaje profundo** estudia las DNNs y, en general, se enfoca en modelos con pilas profundas de c√°lculos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e213c86",
   "metadata": {},
   "source": [
    "Aun as√≠, muchas personas hablan de aprendizaje profundo cada vez que se mencionan redes neuronales (incluso las superficiales).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02347d0d",
   "metadata": {},
   "source": [
    "\n",
    "Durante muchos a√±os, los investigadores lucharon por encontrar una forma de entrenar MLPs sin √©xito. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1dcb12",
   "metadata": {},
   "source": [
    "A principios de los 60, varios investigadores discutieron la posibilidad de usar **descenso de gradiente** para entrenar redes neuronales, pero, como vimos en el Cap√≠tulo 4, esto requiere calcular los gradientes del error del modelo respecto a sus par√°metros. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff94a53b",
   "metadata": {},
   "source": [
    "En ese entonces no estaba claro c√≥mo hacer esto eficientemente en un modelo tan complejo con tantos par√°metros, especialmente con la capacidad computacional de la √©poca.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455f1c0b",
   "metadata": {},
   "source": [
    "\n",
    "En 1970, un investigador llamado **Seppo Linnainmaa** present√≥ en su tesis de maestr√≠a una t√©cnica para calcular todos los gradientes de forma autom√°tica y eficiente. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b92f66",
   "metadata": {},
   "source": [
    "Este algoritmo se conoce hoy como **diferenciaci√≥n autom√°tica en modo inverso** (o **autodiff inverso**). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c41c04",
   "metadata": {},
   "source": [
    "En solo dos pasadas por la red (una hacia adelante y otra hacia atr√°s), puede calcular los gradientes del error de la red neuronal respecto a cada par√°metro del modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fc9432",
   "metadata": {},
   "source": [
    "Es decir, determina c√≥mo ajustar cada peso de conexi√≥n y cada sesgo para reducir el error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f7dbd0",
   "metadata": {},
   "source": [
    " Estos gradientes se usan luego para realizar un paso de descenso de gradiente. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db7fd0e",
   "metadata": {},
   "source": [
    "Si se repite este proceso (calcular gradientes autom√°ticamente y ajustar con descenso de gradiente), el error de la red neuronal disminuir√° gradualmente hasta alcanzar un m√≠nimo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2be18db",
   "metadata": {},
   "source": [
    "Esta combinaci√≥n de autodiff inverso y descenso de gradiente se llama **retropropagaci√≥n** (o **backprop**). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4587b7a9",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "**NOTA**  \n",
    "Existen varias t√©cnicas de autodiff, cada una con pros y contras. El autodiff inverso es ideal cuando la funci√≥n a diferenciar tiene muchas variables (pesos y sesgos) y pocas salidas (una p√©rdida).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4795d168",
   "metadata": {},
   "source": [
    "\n",
    "La retropropagaci√≥n puede aplicarse a todo tipo de grafos computacionales, no solo a redes neuronales: la tesis de Linnainmaa no trataba espec√≠ficamente de redes neuronales, sino de un concepto m√°s general. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68769211",
   "metadata": {},
   "source": [
    "Pasaron varios a√±os antes de que la retropropagaci√≥n se usara ampliamente en redes neuronales.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7af63eb",
   "metadata": {},
   "source": [
    "\n",
    "En 1985, **David Rumelhart, Geoffrey Hinton y Ronald Williams** publicaron un art√≠culo revolucionario que analizaba c√≥mo la retropropagaci√≥n permit√≠a a las redes neuronales aprender representaciones internas √∫tiles. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe154dc2",
   "metadata": {},
   "source": [
    "Sus resultados fueron tan impactantes que la retropropagaci√≥n se populariz√≥ r√°pidamente. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61488b1c",
   "metadata": {},
   "source": [
    "Hoy es, por mucho, la t√©cnica de entrenamiento m√°s usada en redes neuronales.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b27fe1",
   "metadata": {},
   "source": [
    "\n",
    "# Funcionamiento detallado de la retropropagaci√≥n:  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911a1795",
   "metadata": {},
   "source": [
    "1. **Mini-lotes**: Procesa un mini-lote a la vez (ej. 32 instancias) y recorre el conjunto de entrenamiento m√∫ltiples veces. Cada pasada se llama **√©poca**.  \n",
    "2. **Pasada hacia adelante**: El mini-lote entra por la capa de entrada, y se calcula la salida de cada neurona en las capas ocultas, preservando todos los resultados intermedios para la pasada hacia atr√°s.  \n",
    "3. **C√°lculo del error**: Se mide el error de salida usando una **funci√≥n de p√©rdida** que compara la salida deseada con la real.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6557c174",
   "metadata": {},
   "source": [
    "4. **Pasada hacia atr√°s**: Usando la **regla de la cadena**, el algoritmo calcula cu√°nto contribuy√≥ cada peso y sesgo al error, propagando el gradiente del error desde la salida hasta la entrada.  \n",
    "5. **Ajuste de pesos**: Finalmente, se realiza un paso de descenso de gradiente para ajustar los pesos y reducir el error.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b7dbfa",
   "metadata": {},
   "source": [
    "\n",
    "**ADVERTENCIA**  \n",
    "Es crucial inicializar los pesos de las capas ocultas de forma **aleatoria**, de lo contrario el entrenamiento fallar√°. Si todos los pesos y sesgos empiezan en cero, todas las neuronas en una capa ser√°n id√©nticas, y la retropropagaci√≥n las ajustar√° igual, manteniendo la simetr√≠a. Esto har√≠a que la red act√∫e como si tuviera solo una neurona por capa. La inicializaci√≥n aleatoria rompe esta simetr√≠a y permite que la red aprenda diversidad.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a6ff86",
   "metadata": {},
   "source": [
    "\n",
    "En resumen, la retropropagaci√≥n hace predicciones (pasada hacia adelante), mide el error, calcula las contribuciones al error por capa (pasada hacia atr√°s) y ajusta los pesos (descenso de gradiente).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012f3eab",
   "metadata": {},
   "source": [
    "\n",
    "### Activaciones no lineales:  \n",
    "Para que la retropropagaci√≥n funcione, Rumelhart y sus colegas reemplazaron la **funci√≥n escal√≥n** por la **funci√≥n log√≠stica** $(œÉ(z) = 1 / (1 + exp(‚Äìz))$, tambi√©n llamada **sigmoide**). La funci√≥n escal√≥n tiene gradiente cero en todos lados (imposibilitando el descenso de gradiente), mientras que la sigmoide tiene un gradiente bien definido.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2ddbc8",
   "metadata": {},
   "source": [
    "\n",
    "# Otras funciones de activaci√≥n populares: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec049ba",
   "metadata": {},
   "source": [
    " \n",
    "- **Tangente hiperb√≥lica (tanh)**: Similar a la sigmoide, pero con rango de ‚Äì1 a 1, lo que acelera la convergencia.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c2cb10",
   "metadata": {},
   "source": [
    "- **Unidad Lineal Rectificada (ReLU)**: $ReLU(z) = max(0, z)$. No es diferenciable en z = 0, pero en la pr√°ctica es eficiente y evita algunos problemas de gradiente.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a4820f",
   "metadata": {},
   "source": [
    "\n",
    "**¬øPor qu√© son necesarias las funciones de activaci√≥n?**  \n",
    "Si solo se encadenan transformaciones lineales, el resultado sigue siendo lineal. Las activaciones no lineales permiten a las redes aproximar funciones complejas. Una DNN suficientemente grande con activaciones no lineales puede, en teor√≠a, aproximar cualquier funci√≥n continua.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa57e65d",
   "metadata": {},
   "source": [
    "\n",
    "**Figura 10-8.** Funciones de activaci√≥n (izq.) y sus derivadas (der.).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9e739f",
   "metadata": {},
   "source": [
    "\n",
    "¬°Listo! Ahora conoces el origen de las redes neuronales, su arquitectura, c√≥mo se calculan sus salidas y el algoritmo de retropropagaci√≥n. Pero... ¬øpara qu√© sirven exactamente?  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377718d0",
   "metadata": {},
   "source": [
    "\n",
    "### Notas adicionales:  \n",
    "- Se mantuvieron t√©rminos t√©cnicos como *backpropagation* (retropropagaci√≥n) y *ReLU* por ser ampliamente usados en espa√±ol.  \n",
    "- Se ajustaron ejemplos y f√≥rmulas para claridad, conservando su significado original.  \n",
    "- El estilo es t√©cnico pero accesible, dirigido a lectores con conocimientos b√°sicos de machine learning.  \n",
    "\n",
    "¬øNecesitas ajustes o m√°s detalles en alguna secci√≥n?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad7b891",
   "metadata": {},
   "source": [
    "# Pr√°ctica de codificaci√≥n  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3e57a5",
   "metadata": {},
   "source": [
    "\n",
    "Aqu√≠ tienes una **pr√°ctica de codificaci√≥n en Python** enfocada en redes neuronales multicapa (MLP) usando `TensorFlow/Keras`, que cubre los conceptos clave del texto traducido:  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e724ba2",
   "metadata": {},
   "source": [
    "\n",
    "### **Pr√°ctica: Implementaci√≥n de un Perceptr√≥n Multicapa (MLP) con Retropropagaci√≥n** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1deff01",
   "metadata": {},
   "source": [
    " \n",
    "**Objetivos:**  \n",
    "1. Crear un MLP secuencial para clasificaci√≥n.  \n",
    "2. Entender el papel de las funciones de activaci√≥n no lineales.  \n",
    "3. Visualizar el impacto de la inicializaci√≥n de pesos.  \n",
    "4. Monitorizar el entrenamiento con retropropagaci√≥n.  \n",
    "\n",
    "---  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b559bb",
   "metadata": {},
   "source": [
    "\n",
    "### **Paso 1: Configuraci√≥n del Entorno**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e8d6ee8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dense\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.initializers import RandomUniform, Zeros\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3710dcc5",
   "metadata": {},
   "source": [
    "\n",
    "### **Paso 2: Generaci√≥n de Datos**  \n",
    "Usamos el dataset `make_moons` para un problema de clasificaci√≥n no lineal:  \n",
    "```python\n",
    "X, y = make_moons(n_samples=1000, noise=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis')\n",
    "plt.title(\"Dataset de Clasificaci√≥n No Lineal\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### **Paso 3: Implementaci√≥n del MLP con Keras**  \n",
    "#### **Modelo Secuencial con:**  \n",
    "- Capa oculta (4 neuronas, activaci√≥n ReLU).  \n",
    "- Capa de salida (1 neurona, activaci√≥n sigmoide).  \n",
    "- Funci√≥n de p√©rdida: `binary_crossentropy` (para clasificaci√≥n binaria).  \n",
    "- Optimizador: `Adam` (variante de descenso de gradiente).  \n",
    "\n",
    "```python\n",
    "model = Sequential([\n",
    "    Dense(4, activation='relu', input_shape=(2,), kernel_initializer=RandomUniform(minval=-0.5, maxval=0.5)),\n",
    "    Dense(1, activation='sigmoid', kernel_initializer=RandomUniform(minval=-0.5, maxval=0.5))\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "### **Paso 4: Entrenamiento con Retropropagaci√≥n**  \n",
    "```python\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "```\n",
    "\n",
    "### **Paso 5: Visualizaci√≥n de Resultados**  \n",
    "#### **Curvas de Aprendizaje:**  \n",
    "```python\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Test Loss')\n",
    "plt.xlabel('√âpocas')\n",
    "plt.ylabel('P√©rdida')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### **Frontera de Decisi√≥n:**  \n",
    "```python\n",
    "def plot_decision_boundary(model, X, y):\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, levels=0.5, cmap='RdBu')\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap='viridis')\n",
    "    plt.title(\"Frontera de Decisi√≥n del MLP\")\n",
    "    plt.show()\n",
    "\n",
    "plot_decision_boundary(model, X_test, y_test)\n",
    "```\n",
    "\n",
    "### **Paso 6: Experimentos Adicionales**  \n",
    "#### **1. Inicializaci√≥n de Pesos a Cero (¬°Advertencia!)**  \n",
    "```python\n",
    "model_zero_init = Sequential([\n",
    "    Dense(4, activation='relu', input_shape=(2,), kernel_initializer=Zeros()),\n",
    "    Dense(1, activation='sigmoid', kernel_initializer=Zeros())\n",
    "])\n",
    "model_zero_init.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "model_zero_init.fit(X_train, y_train, epochs=100, verbose=0)\n",
    "print(\"Precisi√≥n con pesos en cero:\", accuracy_score(y_test, model_zero_init.predict(X_test) > 0.5))\n",
    "```\n",
    "\n",
    "#### **2. Comparaci√≥n de Funciones de Activaci√≥n**  \n",
    "```python\n",
    "activations = ['relu', 'tanh', 'sigmoid']\n",
    "for activation in activations:\n",
    "    model_act = Sequential([\n",
    "        Dense(4, activation=activation, input_shape=(2,)),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model_act.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    model_act.fit(X_train, y_train, epochs=100, verbose=0)\n",
    "    print(f\"Precisi√≥n con {activation}:\", accuracy_score(y_test, model_act.predict(X_test) > 0.5))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusiones de la Pr√°ctica:**  \n",
    "- **Retropropagaci√≥n:** El modelo ajusta autom√°ticamente los pesos mediante `model.fit()`.  \n",
    "- **Funciones de Activaci√≥n:** ReLU suele ser m√°s eficiente que sigmoide/tanh en capas ocultas.  \n",
    "- **Inicializaci√≥n:** Los pesos aleatorios rompen la simetr√≠a y permiten el aprendizaje.  \n",
    "- **Batch y √âpocas:** El mini-batch (`batch_size=32`) acelera el entrenamiento.  \n",
    "\n",
    "**Salida Esperada:**  \n",
    "- Gr√°ficos de p√©rdida decreciente.  \n",
    "- Frontera de decisi√≥n no lineal que separa las clases.  \n",
    "- Precisi√≥n > 90% con inicializaci√≥n adecuada.  \n",
    "\n",
    "---  \n",
    "\n",
    "**¬øQu√© m√°s te gustar√≠a explorar?** Por ejemplo:  \n",
    "- A√±adir m√°s capas ocultas para crear una DNN.  \n",
    "- Regularizaci√≥n con Dropout.  \n",
    "- Optimizaci√≥n de hiperpar√°metros.  \n",
    "\n",
    "¬°Espero que esta pr√°ctica te ayude a dominar los MLPs! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
